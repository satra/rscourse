{
 "metadata": {
  "_draft": {
   "nbviewer_url": "gisting : nipype.ipynb\r\n"
  },
  "name": "",
  "signature": "sha256:f2b97de4d914b704ac3a5bf92cabd43315914ab42ceac5f730f9d867d9aa5a36"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Optimizing preprocessing with Nipype\n",
      "\n",
      "<center>\n",
      "Nipype team | contact: satra@mit.edu  |  nipy.org/nipype\n",
      "<br>\n",
      "(Hit Esc to get an overview)\n",
      "</center>[Latest version][notebook] | [Latest slideshow][slideshow]\n",
      "\n",
      "[notebook]: http://nbviewer.ipython.org/urls/raw.github.com/satra/rscourse/master/brainconnect-tutorial.ipynb\n",
      "[slideshow]: http://slideviewer.herokuapp.com/url/raw.github.com/satra/rscourse/master/brainconnect-tutorial.ipynb"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Contributors\n",
      "\n",
      "http://nipy.org/nipype/about.html#code-contributors\n",
      "\n",
      "# Funding\n",
      "\n",
      "- 1R03EB008673-01 from NIBIB, Satrajit Ghosh, Susan Whitfield-Gabrieli\n",
      "- 5R01MH081909-02 from NIMH, Mark D'Esposito\n",
      "- INCF\n",
      "\n",
      "# Conflict of interest\n",
      "\n",
      "<center>\n",
      "Satrajit Ghosh: TankThink Labs, LLC\n",
      "</center>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Outline\n",
      "\n",
      "1. What is Nipype?\n",
      "2. Preprocessing dissection\n",
      "3. Optimizing preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# What is Nipype?\n",
      "\n",
      "<center>\n",
      "<img src=\"https://raw.github.com/satra/intro2nipype/master/images/nipype.png\" width=\"40%\" />\n",
      "<br>\n",
      "Figure designed and created by: Arno Klein (www.mindboggle.info)\n",
      "</center>\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Make life a little easier\n",
      "\n",
      "<img src=\"https://raw.github.com/satra/intro2nipype/master/images/EDC.png\" />\n",
      "\n",
      "Poline _et al._ (2012)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Many workflow systems out there\n",
      "\n",
      "- [BioImage Suite](http://www.bioimagesuite.org/)\n",
      "- [BIRN Tools](https://wiki.birncommunity.org/x/LgFrAQ)\n",
      "- [BrainVisa](http://brainvisa.info)\n",
      "- [CambaFX](http://www-bmu.psychiatry.cam.ac.uk/software/)\n",
      "- [JIST for MIPAV](http://www.nitrc.org/projects/jist/)\n",
      "- [LONI pipeline](http://pipeline.loni.ucla.edu)\n",
      "- [MEVIS Lab](http://www.mevislab.de)\n",
      "- [PSOM](http://code.google.com/p/psom/)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Solution requirements\n",
      "\n",
      "Coming at it from a developer's perspective, we needed something\n",
      "\n",
      "- lightweight\n",
      "- scriptable\n",
      "- provided formal, common semantics\n",
      "- allowed interactive exploration\n",
      "- supported efficient batch processing\n",
      "- enabled rapid algorithm prototyping\n",
      "- was flexible and adaptive\n",
      "- part of an ecosystem"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Python ecosystem\n",
      "<table width=\"768px\">\n",
      "<tr>\n",
      "<td colspan=\"2\"><a href=\"http://ipython.org/\"><img src=\"http://ipython.org/_static/IPy_header.png\"></a></td>\n",
      "<td colspan=\"2\"><a href=\"http://nipy.org/\"><img src=\"http://nipy.org/_static/nipy-community-banner-gy.png\"></a></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><a href=\"http://scipy.org/\"><img src=\"http://www.scipy.org/_static/images/tutorial.png\"></a></td>\n",
      "<td><a href=\"http://numpy.org/\"><img src=\"http://www.numpy.org/_static/numpy_logo.png\"></a></td>\n",
      "<td><a href=\"http://pymvpa.org/\"><img src=\"http://www.pymvpa.org/_static/pymvpa_logo.jpg\" width=\"256\"></a></td>\n",
      "<td><a href=\"http://scikit-learn.org/\"><img src=\"http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\"></a></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><a href=\"http://networkx.github.io/\"><img src=\"https://raw.github.com/networkx/networkx/master/doc/source/static/art1.png\" width=\"256\"></a></td>\n",
      "<td><a href=\"http://matplotlib.org/\"><img src=\"http://matplotlib.org/_static/logo2.png\" width=\"256\"></a></td>\n",
      "<td><a href=\"http://code.enthought.com/projects/mayavi/\"><img src=\"http://code.enthought.com/img/mayavi-samp.png\" width=\"256\"></a></td>\n",
      "<td><a href=\"http://neuro.debian.net/\"><img src=\"http://neuro.debian.net/_files/neurodebian_logo_posters_banner.svg\" width=\"256\"></a></td>\n",
      "</tr>\n",
      "</table>\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "#Existing technologies\n",
      "\n",
      "**shell scripting**:\n",
      "\n",
      "  Can be quick to do, and powerful, but only provides application specific \n",
      "  scalability, and not easy to port across different architectures.\n",
      "\n",
      "**make/CMake**:\n",
      "\n",
      "  Similar in concept to workflow execution in Nipype, but again limited by the\n",
      "  need for command line tools and flexibility in terms of scaling across\n",
      "  hardware architectures (although see [makeflow](http://nd.edu/~ccl/software/makeflow).\n",
      "\n",
      "**Octave/MATLAB**:\n",
      "\n",
      "  Integration with other tools is *ad hoc* (i.e., system call) and dataflow is\n",
      "  managed at a programmatic level. However, see [PSOM](http://code.google.com/p/psom/) which offers a nice\n",
      "  alternative to some aspects of Nipype for Octave/Matlab users.\n",
      "\n",
      "**Graphical options**: (e.g., [LONI Pipeline](http://pipeline.loni.ucla.edu), [VisTrails](http://www.vistrails.org/))\n",
      "\n",
      "  Are easy to use but reduces flexibility relative to scripting options."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Nipype architecture\n",
      "\n",
      "<img src=\"https://raw.github.com/satra/intro2nipype/master/images/arch.png\" width=\"100%\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "* **Interface**: Wraps a program or function\n",
      "\n",
      "- **Node/MapNode**: Wraps an `Interface` for use in a Workflow that provides\n",
      "  caching and other goodies (e.g., pseudo-sandbox)\n",
      "- **Workflow**: A *graph* or *forest of graphs* whose nodes are of type `Node`,\n",
      "  `MapNode` or `Workflow` and whose edges represent data flow\n",
      "\n",
      "* **Plugin**: A component that describes how a `Workflow` should be executed"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "#Software interfaces\n",
      "\n",
      "Currently supported (5-2-2013). [Click here for latest](http://www.mit.edu/~satra/nipype-nightly/documentation.html)\n",
      "\n",
      "<style>\n",
      ".rendered_html table{border:0px}\n",
      ".rendered_html tr{border:0px}\n",
      ".rendered_html td{border:0px}\n",
      "</style>\n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<td>\n",
      "<ul>\n",
      "<li><a href=\"http://afni.nimh.nih.gov/afni\">AFNI</a></li>\n",
      "<li><a href=\"http://www.picsl.upenn.edu/ANTS\">ANTS</a></li>\n",
      "<li><a href=\"http://www.psychiatry.uiowa.edu/mhcrc/IPLpages/BRAINS.htm\">BRAINS</a></li>\n",
      "<li><a href=\"http://www.cs.ucl.ac.uk/research/medic/camino\">Camino</a></li>\n",
      "<li><a href=\"http://www.nitrc.org/projects/camino-trackvis\">Camino-TrackVis</a></li>\n",
      "<li><a href=\"http://www.connectomeviewer.org\">ConnectomeViewerToolkit</a></li>\n",
      "<li><a href=\"http://www.cabiatl.com/mricro/mricron/dcm2nii.html\">dcm2nii</a></li>\n",
      "<li><a href=\"http://www.trackvis.org/dtk\">Diffusion Toolkit</a></li>\n",
      "</ul>\n",
      "</td>\n",
      "<td>\n",
      "<ul>\n",
      "<li><a href=\"http://freesurfer.net\">FreeSurfer</a></li>\n",
      "<li><a href=\"http://www.fmrib.ox.ac.uk/fsl\">FSL</a></li>\n",
      "<li><a href=\"http://www.brain.org.au/software/mrtrix/index.html\">MRtrx</a></li>\n",
      "<li><a href=\"http://nipy.org/nipy\">Nipy</a></li>\n",
      "<li><a href=\"http://nipy.org/nitime\">Nitime</a></li>\n",
      "<li><a href=\"http://github.com/pyxnat\">PyXNAT</a></li>\n",
      "<li><a href=\"http://www.slicer.org\">Slicer</a></li>\n",
      "<li><a href=\"http://www.fil.ion.ucl.ac.uk/spm\">SPM</a></li>\n",
      "</ul>\n",
      "</td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "Most used/contributed policy!\n",
      "\n",
      "Not all components of these packages are available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "source": [
      "# Workflows\n",
      "\n",
      "- Properties:\n",
      "\n",
      "    - processing pipeline is a directed acyclic graph (DAG)\n",
      "    - nodes are processes\n",
      "    - edges represent data flow\n",
      "    - compact represenation for any process\n",
      "    - code and data separation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "#Execution Plugins\n",
      "\n",
      "Allows seamless execution across many architectures\n",
      "\n",
      "  - Local\n",
      "\n",
      "    - Serial\n",
      "    - Multicore\n",
      "\n",
      "  - Clusters\n",
      "\n",
      "    - SLURM\n",
      "    - HTCondor\n",
      "    - PBS/Torque/SGE/LSF (native and via IPython)\n",
      "    - SSH (via IPython)\n",
      "    - Soma Workflow"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Learn Nipype concepts in 10 easy steps\n",
      "\n",
      "</center>[Latest version][notebook] | [Latest slideshow][slideshow]\n",
      "\n",
      "[notebook]: http://nbviewer.ipython.org/urls/raw.github.com/nipy/nipype/master/examples/nipype_tutorial.ipynb\n",
      "[slideshow]: http://slideviewer.herokuapp.com/url/raw.github.com/nipy/nipype/master/examples/nipype_tutorial.ipynb"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Dissecting preprocessing\n",
      "\n",
      "1. A basic preprocessing workflow\n",
      "\n",
      "2. Adding on some extra features\n",
      "\n",
      "(Focus on SPM, FSL tools)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Step 1. A basic preprocessing workflow\n",
      "\n",
      "1. Realignment\n",
      "2. Slice Timing correction\n",
      "3. Coregistration\n",
      "4. Smoothing\n",
      "5. Bandpass filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Step 0. Import all the necessary pieces in Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "matlab_mcr = True\n",
      "from nipype.interfaces import spm\n",
      "\n",
      "# Use MCR\n",
      "if matlab_mcr:\n",
      "    matlab_cmd = '/home/rscourse/run_spm8.sh /usr/local/MATLAB/MATLAB_Compiler_Runtime/v82/ script'\n",
      "    spm.SPMCommand.set_mlab_paths(matlab_cmd=matlab_cmd, use_mcr=True)\n",
      "else:\n",
      "    from nipype.interfaces import matlab as mlab\n",
      "    mlab.MatlabCommand.set_default_matlab_cmd(\"matlab -nodisplay\")\n",
      "    # If SPM is not in your MATLAB path you should add it here\n",
      "    # mlab.MatlabCommand.set_default_paths('/path/to/your/spm8')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nipype.interfaces.base import CommandLine\n",
      "CommandLine.set_default_terminal_output('allatonce')\n",
      "\n",
      "from nipype.interfaces import (fsl, Function)\n",
      "fsl.FSLCommand.set_default_output_type('NIFTI')\n",
      "\n",
      "from nipype import Workflow, Node, MapNode\n",
      "from nipype.algorithms.rapidart import ArtifactDetect\n",
      "from nipype.interfaces.utility import Rename\n",
      "from nipype.utils.filemanip import filename_to_list\n",
      "\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import nibabel as nb\n",
      "from IPython.display import Image"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Let's get some data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os.path as op\n",
      "from glob import glob\n",
      "\n",
      "subj_id = 'SUB_1024011'\n",
      "TR = 2.0\n",
      "num_slices = 33\n",
      "lowpass_freq = 0.1\n",
      "highpass_freq = 0.01\n",
      "\n",
      "data_dir = '/s3mount/bb/TUTORIAL_DATA/RAW_DATA'\n",
      "files = sorted(glob(op.join(data_dir,\n",
      "                            '%s/E?/func/rest.nii' % subj_id)))\n",
      "anat_file = glob(op.join(data_dir,\n",
      "                         '%s/EO/anat/anat.nii' % subj_id))[0]\n",
      "\n",
      "print(\"Functional Data: \", files)\n",
      "print(\"Anatomical Data: \", anat_file)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Set up the basic workflow\n",
      "\n",
      "#### First create a workflow object"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wf = Workflow(name='preprocess1')"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Use a Node to rename files to ensure uniqueness"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "name_unique = MapNode(Rename(format_string='rest_%(run)02d'),\n",
      "                      iterfield=['in_file', 'run'],\n",
      "                      name='rename')\n",
      "name_unique.inputs.keep_ext = True\n",
      "name_unique.inputs.run = range(1, len(files) + 1)\n",
      "name_unique.inputs.in_file = files"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Create a realign Node using SPM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "realign = Node(interface=spm.Realign(), name=\"realign\")\n",
      "realign.inputs.jobtype = 'estwrite'"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Connect it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wf.connect(name_unique, 'out_file', realign, 'in_files')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Add the slice timing node\n",
      "\n",
      "#### Use `nipype.interfaces.spm.SliceTiming` to compensate for temporal shifts in the slice acquisition order"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "slice_timing = Node(interface=spm.SliceTiming(), name=\"slice_timing\")\n",
      "slice_timing.inputs.num_slices = num_slices\n",
      "slice_timing.inputs.time_repetition = TR\n",
      "slice_timing.inputs.time_acquisition = TR - TR/float(num_slices)\n",
      "slice_timing.inputs.ref_slice = int(num_slices/2)"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Adjust slice order for Siemens scanners"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if num_slices % 2 == 1:\n",
      "    # odd\n",
      "    slice_timing.inputs.slice_order = range(1, num_slices + 1, 2) + range(2, num_slices + 1, 2)\n",
      "else:\n",
      "    # even\n",
      "    slice_timing.inputs.slice_order = range(2, num_slices + 1, 2) + range(1, num_slices + 1, 2)"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### and connect it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wf.connect(realign, 'realigned_files', slice_timing, 'in_files')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Add the structural element"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Use `nipype.interfaces.spm.Coregister` to perform a rigid body registration of the functional data to the structural data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coregister = Node(interface=spm.Coregister(), name=\"coregister\")\n",
      "coregister.inputs.jobtype = 'estimate'\n",
      "coregister.inputs.target = anat_file"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Use `nipype.interfaces.spm.Segment` to segment the anatomical image and normalize it to MNI space."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "segment = Node(interface=spm.Segment(), name=\"segment\")\n",
      "segment.inputs.save_bias_corrected = True\n",
      "segment.inputs.data = anat_file"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Connect the nodes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wf.connect(realign, 'mean_image', coregister, 'source')\n",
      "wf.connect(slice_timing, 'timecorrected_files', coregister, 'apply_to_files')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Connect the structural and functional pieces"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Warp functional and structural data to SPM's T1 template using `nipype.interfaces.spm.Normalize`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "normalize_func = Node(spm.Normalize(), name=\"normalize_func\")\n",
      "normalize_func.inputs.jobtype = \"write\"\n",
      "normalize_func.inputs.write_voxel_sizes =[2., 2., 2.]"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Smooth the functional data using `nipype.interfaces.spm.Smooth`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "smooth = Node(interface=spm.Smooth(), name = \"smooth\")"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Here we connect the remaining nodes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wf.connect([(segment, normalize_func, \n",
      "             [('transformation_mat', 'parameter_file')]),\n",
      "            (coregister, normalize_func, \n",
      "             [('coregistered_files', 'apply_to_files')]),\n",
      "            (normalize_func, smooth, \n",
      "             [('normalized_files', 'in_files')]),\n",
      "            ])"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# The last step (sort of)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bandpass_filter(files, fs, lowpass_freq=-1, highpass_freq=-1):\n",
      "    out_files = []\n",
      "    for filename in filename_to_list(files):\n",
      "        _, name, ext = split_filename(filename)\n",
      "        out_file = os.path.join(os.getcwd(), name + '_bp' + ext)\n",
      "        img = nb.load(filename)\n",
      "        timepoints = img.shape[-1]\n",
      "        F = np.zeros((timepoints))\n",
      "        lowidx = timepoints/2 + 1\n",
      "        if lowpass_freq > 0:\n",
      "            lowidx = np.round(lowpass_freq / fs * timepoints)\n",
      "        highidx = 0\n",
      "        if highpass_freq > 0:\n",
      "            highidx = np.round(highpass_freq / fs * timepoints)\n",
      "        F[highidx:lowidx] = 1\n",
      "        F = ((F + F[::-1]) > 0).astype(int)\n",
      "        data = img.get_data()\n",
      "        if np.all(F == 1):\n",
      "            filtered_data = data\n",
      "        else:\n",
      "            filtered_data = np.real(np.fft.ifftn(np.fft.fftn(data) * F))\n",
      "        img_out = nb.Nifti1Image(filtered_data, img.get_affine(),\n",
      "                                 img.get_header())\n",
      "        img_out.to_filename(out_file)\n",
      "        out_files.append(out_file)\n",
      "    return list_to_filename(out_files)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Add the bandpass filter node"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Filter the smoothed data using a custom bandpass filter (a boxcar fft filter)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imports = ['import os',\n",
      "           'import nibabel as nb',\n",
      "           'import numpy as np',\n",
      "           'import scipy as sp',\n",
      "           'from nipype.utils.filemanip import filename_to_list, list_to_filename, split_filename',\n",
      "           'from scipy.special import legendre'\n",
      "           ]\n",
      "bandpass = Node(Function(input_names=['files', 'lowpass_freq',\n",
      "                                       'highpass_freq', 'fs'],\n",
      "                          output_names=['out_files'],\n",
      "                          function=bandpass_filter,\n",
      "                          imports=imports),\n",
      "                 name='bandpass')\n",
      "bandpass.inputs.fs = 1./TR\n",
      "bandpass.inputs.highpass_freq = highpass_freq\n",
      "bandpass.inputs.lowpass_freq = lowpass_freq"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### And connect it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wf.connect(smooth, 'smoothed_files', bandpass, 'files')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# What do we have"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wf.write_graph(graph2use='flat')\n",
      "Image(filename='graph.dot.png')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Now run the workflow"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wf.base_dir = '/mnt/scratch/nipype/'\n",
      "wf.run()\n",
      "# wf.run('MultiProc')\n",
      "# wf.run('SGE')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Now let's add a few additional components\n",
      "\n",
      "1. Two streams:\n",
      "\n",
      "   - smoothed\n",
      "   - unsmoothed\n",
      "\n",
      "2. Estimating outliers and filtering motion and outliers\n",
      "\n",
      "3. Estimating and filtering CompCor from eroded white matter and csf masks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wf = Workflow(name='preprocess2')\n",
      "\n",
      "# Rename files in case they are named identically\n",
      "name_unique = MapNode(Rename(format_string='rest_%(run)02d'),\n",
      "                      iterfield=['in_file', 'run'],\n",
      "                      name='rename')\n",
      "name_unique.inputs.keep_ext = True\n",
      "name_unique.inputs.run = range(1, len(files) + 1)\n",
      "name_unique.inputs.in_file = files\n",
      "\n",
      "# Create a realign Node using SPM\n",
      "realign = Node(interface=spm.Realign(), name=\"realign\")\n",
      "realign.inputs.jobtype = 'estwrite'\n",
      "\n",
      "wf.connect(name_unique, 'out_file', realign, 'in_files')\n",
      "\n",
      "\"\"\"Use :class:`nipype.interfaces.spm.SliceTimeing` to compensate for\n",
      "temporal shifts in the slice acquisition order\n",
      "\"\"\"\n",
      "\n",
      "slice_timing = Node(interface=spm.SliceTiming(), name=\"slice_timing\")\n",
      "slice_timing.inputs.num_slices = num_slices\n",
      "slice_timing.inputs.time_repetition = TR\n",
      "slice_timing.inputs.time_acquisition = TR - TR/float(num_slices)\n",
      "if num_slices % 2 == 1:\n",
      "    # odd\n",
      "    slice_timing.inputs.slice_order = range(1, num_slices + 1, 2) + range(2, num_slices + 1, 2)\n",
      "else:\n",
      "    # even\n",
      "    slice_timing.inputs.slice_order = range(2, num_slices + 1, 2) + range(1, num_slices + 1, 2)\n",
      "slice_timing.inputs.ref_slice = int(num_slices/2)\n",
      "\n",
      "# and connect it\n",
      "wf.connect(realign, 'realigned_files', slice_timing, 'in_files')\n",
      "\n",
      "\"\"\"Use :class:`nipype.interfaces.spm.Coregister` to perform a rigid\n",
      "body registration of the functional data to the structural data.\n",
      "\"\"\"\n",
      "\n",
      "coregister = Node(interface=spm.Coregister(), name=\"coregister\")\n",
      "coregister.inputs.jobtype = 'estimate'\n",
      "coregister.inputs.target = anat_file\n",
      "\n",
      "\"\"\"Use :class:`nipype.interfaces.spm.Segment` to segment the \n",
      "anatomical image and normalize it MNI space.\n",
      "\"\"\"\n",
      "\n",
      "segment = Node(interface=spm.Segment(), name=\"segment\")\n",
      "segment.inputs.save_bias_corrected = True\n",
      "segment.inputs.data = anat_file\n",
      "\n",
      "wf.connect(realign, 'mean_image', coregister, 'source')\n",
      "wf.connect(slice_timing, 'timecorrected_files', coregister, 'apply_to_files')\n",
      "\n",
      "\n",
      "\"\"\"Warp functional and structural data to SPM's T1 template using\n",
      ":class:`nipype.interfaces.spm.Normalize`.  The tutorial data set\n",
      "includes the template image, T1.nii.\n",
      "\"\"\"\n",
      "\n",
      "normalize_func = Node(interface=spm.Normalize(), name = \"normalize_func\")\n",
      "normalize_func.inputs.jobtype = \"write\"\n",
      "normalize_func.inputs.write_voxel_sizes =[2., 2., 2.]\n",
      "\n",
      "\"\"\"Smooth the functional data using\n",
      ":class:`nipype.interfaces.spm.Smooth`.\n",
      "\"\"\"\n",
      "\n",
      "smooth = Node(interface=spm.Smooth(), name = \"smooth\")\n",
      "\n",
      "\"\"\"Here we connect the remaining nodes.\n",
      "\"\"\"\n",
      "\n",
      "wf.connect([(segment, normalize_func, [('transformation_mat', 'parameter_file')]),\n",
      "            (coregister, normalize_func, [('coregistered_files', 'apply_to_files')]),\n",
      "            (normalize_func, smooth, [('normalized_files', 'in_files')]),\n",
      "            ])"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Add an outlier detection node"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Use `nipype.algorithms.rapidart` to determine which of the images in the functional series are outliers based on deviations in intensity or movement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm_threshold = 1\n",
      "\n",
      "art = Node(interface=ArtifactDetect(), name=\"art\")\n",
      "art.inputs.use_differences = [True, False]\n",
      "art.inputs.use_norm = True\n",
      "art.inputs.norm_threshold = norm_threshold\n",
      "art.inputs.zintensity_threshold = 3\n",
      "art.inputs.mask_type = 'spm_global'\n",
      "art.inputs.parameter_source = 'SPM'\n",
      "\n",
      "wf.connect([(realign, art, [('realignment_parameters', 'realignment_parameters')]),\n",
      "            (smooth, art, [('smoothed_files', 'realigned_files')]),\n",
      "            ])"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Tissue classes from anatomical segmentation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "segment.inputs.wm_output_type = [False, False, True]\n",
      "segment.inputs.csf_output_type = [False, False, True]"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Combine the tissue classes into a list"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "merge = Node(Merge(2), name='merge')\n",
      "wf.connect(segment, 'native_wm_image', merge, 'in1')\n",
      "wf.connect(segment, 'native_csf_image', merge, 'in2')"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### Normalize the tissue classes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "normalize_segs = Node(interface=spm.Normalize(), name = \"normalize_segs\")\n",
      "normalize_segs.inputs.jobtype = \"write\"\n",
      "normalize_segs.inputs.write_voxel_sizes = [2., 2., 2.]\n",
      "\n",
      "wf.connect(merge, 'out_file', normalize_segs, 'apply_to_files')\n",
      "wf.connect(segment, 'transformation_mat', normalize_segs, 'parameter_file')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Get conservative white matter and csf masks\n",
      "\n",
      "#### Use FSL's math program\n",
      "\n",
      "- threshold\n",
      "- binarize\n",
      "- erode"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bin_and_erode = MapNode(fsl.ImageMaths(),\n",
      "                        iterfield=['in_file'],\n",
      "                        name='bin_and_erode')\n",
      "bin_and_erode.inputs.op_string = '-thr 0.99 -bin -ero'\n",
      "\n",
      "wf.connect(normalize_segs, 'normalized_files',\n",
      "           bin_and_erode, 'in_file')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Transform motion parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def motion_regressors(motion_params, order=0, derivatives=1):\n",
      "    \"\"\"Compute motion regressors upto given order and derivative\n",
      "\n",
      "    motion + d(motion)/dt + d2(motion)/dt2 (linear + quadratic)\n",
      "    \"\"\"\n",
      "    out_files = []\n",
      "    for idx, filename in enumerate(filename_to_list(motion_params)):\n",
      "        params = np.genfromtxt(filename)\n",
      "        out_params = params\n",
      "        for d in range(1, derivatives + 1):\n",
      "            cparams = np.vstack((np.repeat(params[0, :][None, :], d, axis=0),\n",
      "                                 params))\n",
      "            out_params = np.hstack((out_params, np.diff(cparams, d, axis=0)))\n",
      "        out_params2 = out_params\n",
      "        for i in range(2, order + 1):\n",
      "            out_params2 = np.hstack((out_params2, np.power(out_params, i)))\n",
      "        filename = os.path.join(os.getcwd(), \"motion_regressor%02d.txt\" % idx)\n",
      "        np.savetxt(filename, out_params2, fmt=\"%.10f\")\n",
      "        out_files.append(filename)\n",
      "    return out_files"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Compute motion regressors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "motreg = Node(Function(input_names=['motion_params', 'order',\n",
      "                                    'derivatives'],\n",
      "                       output_names=['out_files'],\n",
      "                       function=motion_regressors,\n",
      "                       imports=imports),\n",
      "              name='getmotionregress')\n",
      "motreg.inputs.order = 1\n",
      "motreg.inputs.derivatives = 1\n",
      "wf.connect(realign, 'realignment_parameters', motreg, 'motion_params')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Define the function to create the filter for motion and outliers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_filter1(motion_params, comp_norm, outliers, detrend_poly=None):\n",
      "    \"\"\"Builds regressor set: (motion parameters, composite norm, outliers, detrend)\n",
      "    \"\"\"\n",
      "    out_files = []\n",
      "    for idx, filename in enumerate(filename_to_list(motion_params)):\n",
      "        params = np.genfromtxt(filename)\n",
      "        norm_val = np.genfromtxt(filename_to_list(comp_norm)[idx])\n",
      "        out_params = np.hstack((params, norm_val[:, None]))\n",
      "        try:\n",
      "            outlier_val = np.genfromtxt(filename_to_list(outliers)[idx])\n",
      "        except IOError:\n",
      "            outlier_val = np.empty((0))\n",
      "        for index in np.atleast_1d(outlier_val):\n",
      "            outlier_vector = np.zeros((out_params.shape[0], 1))\n",
      "            outlier_vector[index] = 1\n",
      "            out_params = np.hstack((out_params, outlier_vector))\n",
      "        if detrend_poly:\n",
      "            timepoints = out_params.shape[0]\n",
      "            X = np.ones((timepoints, 1))\n",
      "            for i in range(detrend_poly):\n",
      "                X = np.hstack((X, legendre(\n",
      "                    i + 1)(np.linspace(-1, 1, timepoints))[:, None]))\n",
      "            out_params = np.hstack((out_params, X))\n",
      "        filename = os.path.join(os.getcwd(), \"filter_regressor%02d.txt\" % idx)\n",
      "        np.savetxt(filename, out_params, fmt=\"%.10f\")\n",
      "        out_files.append(filename)\n",
      "    return out_files"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Now create and remove the noise\n",
      "\n",
      "#### Create a filter to remove motion and art confounds"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "createfilter1 = Node(Function(input_names=['motion_params', 'comp_norm',\n",
      "                                           'outliers', 'detrend_poly'],\n",
      "                              output_names=['out_files'],\n",
      "                              function=build_filter1,\n",
      "                              imports=imports),\n",
      "                     name='makemotionbasedfilter')\n",
      "createfilter1.inputs.detrend_poly = 2\n",
      "wf.connect(motreg, 'out_files', createfilter1, 'motion_params')\n",
      "wf.connect(art, 'norm_files', createfilter1, 'comp_norm')\n",
      "wf.connect(art, 'outlier_files', createfilter1, 'outliers')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Add another function\n",
      "\n",
      "#### Create a function to set output names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rename(in_files, suffix=None):\n",
      "    from nipype.utils.filemanip import (filename_to_list, split_filename,\n",
      "                                        list_to_filename)\n",
      "    out_files = []\n",
      "    for idx, filename in enumerate(filename_to_list(in_files)):\n",
      "        _, name, ext = split_filename(filename)\n",
      "        if suffix is None:\n",
      "            out_files.append(name + ('_%03d' % idx) + ext)\n",
      "        else:\n",
      "            out_files.append(name + suffix + ext)\n",
      "    return list_to_filename(out_files)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Remove motion, outlier and detrend"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter1 = MapNode(fsl.GLM(out_f_name='F_mcart.nii',\n",
      "                          out_pf_name='pF_mcart.nii',\n",
      "                          demean=True),\n",
      "                  iterfield=['in_file', 'design', 'out_res_name'],\n",
      "                  name='filtermotion')\n",
      "\n",
      "wf.connect(normalize_func, 'normalized_files', filter1, 'in_file')\n",
      "wf.connect(normalize_func, ('normalized_files', rename, '_filtermotart'),\n",
      "           filter1, 'out_res_name')\n",
      "wf.connect(createfilter1, 'out_files', filter1, 'design')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Define the function to estimate the nuisance time series using CompCor "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_noise_components(realigned_file, mask_file, num_components=5,\n",
      "                             extra_regressors=None):\n",
      "    \"\"\"Extract components most reflective of physiological noise\n",
      "    \"\"\"\n",
      "    imgseries = nb.load(realigned_file)\n",
      "    components = None\n",
      "    for filename in filename_to_list(mask_file):\n",
      "        mask = nb.load(filename).get_data()\n",
      "        if len(np.nonzero(mask > 0)[0]) == 0:\n",
      "            continue\n",
      "        voxel_timecourses = imgseries.get_data()[mask > 0]\n",
      "        voxel_timecourses[np.isnan(np.sum(voxel_timecourses, axis=1)), :] = 0\n",
      "        # remove mean and normalize by variance\n",
      "        X = voxel_timecourses.T\n",
      "        stdX = np.std(X, axis=0)\n",
      "        stdX[stdX == 0] = 1.\n",
      "        stdX[np.isnan(stdX)] = 1.\n",
      "        stdX[np.isinf(stdX)] = 1.\n",
      "        X = (X - np.mean(X, axis=0))/stdX\n",
      "        u, _, _ = sp.linalg.svd(X, full_matrices=False)\n",
      "        if components is None:\n",
      "            components = u[:, :num_components]\n",
      "        else:\n",
      "            components = np.hstack((components, u[:, :num_components]))\n",
      "    if extra_regressors:\n",
      "        regressors = np.genfromtxt(extra_regressors)\n",
      "        components = np.hstack((components, regressors))\n",
      "    components_file = os.path.join(os.getcwd(), 'noise_components.txt')\n",
      "    np.savetxt(components_file, components, fmt=\"%.10f\")\n",
      "    return components_file"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Now estimate and remove the noise"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "createfilter2 = MapNode(Function(input_names=['realigned_file', 'mask_file',\n",
      "                                              'num_components',\n",
      "                                              'extra_regressors'],\n",
      "                                 output_names=['out_files'],\n",
      "                                 function=extract_noise_components,\n",
      "                                 imports=imports),\n",
      "                        iterfield=['realigned_file', 'extra_regressors'],\n",
      "                        name='makecompcorrfilter')\n",
      "createfilter2.inputs.num_components = 5\n",
      "\n",
      "wf.connect(createfilter1, 'out_files', createfilter2, 'extra_regressors')\n",
      "wf.connect(filter1, 'out_res', createfilter2, 'realigned_file')\n",
      "wf.connect(bin_and_erode, 'out_file', createfilter2, 'mask_file')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Remove it from both the unsmoothed and smoothed data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter2 = MapNode(fsl.GLM(out_f_name='F.nii',\n",
      "                          out_pf_name='pF.nii',\n",
      "                          demean=True),\n",
      "                  iterfield=['in_file', 'design', 'out_res_name'],\n",
      "                  name='filter_noise_nosmooth')\n",
      "wf.connect(normalize_func, 'normalized_files', filter2, 'in_file')\n",
      "wf.connect(normalize_func, ('normalized_files', rename, '_unsmooth_cleaned'),\n",
      "           filter2, 'out_res_name')\n",
      "wf.connect(createfilter2, 'out_files', filter2, 'design')"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter3 = MapNode(fsl.GLM(out_f_name='F.nii',\n",
      "                          out_pf_name='pF.nii',\n",
      "                          demean=True),\n",
      "                  iterfield=['in_file', 'design', 'out_res_name'],\n",
      "                  name='filter_noise_smooth')\n",
      "wf.connect(smooth, ('smoothed_files', rename, '_cleaned'),\n",
      "           filter3, 'out_res_name')\n",
      "wf.connect(smooth, 'smoothed_files', filter3, 'in_file')\n",
      "wf.connect(createfilter2, 'out_files', filter3, 'design')\n",
      "#wf.connect(masktransform, 'transformed_file', filter3, 'mask')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# Filter the data - with a bandpass filter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bandpass1 = Node(Function(input_names=['files', 'lowpass_freq',\n",
      "                                       'highpass_freq', 'fs'],\n",
      "                          output_names=['out_files'],\n",
      "                          function=bandpass_filter,\n",
      "                          imports=imports),\n",
      "                 name='bandpass_unsmooth')\n",
      "bandpass1.inputs.fs = 1./TR\n",
      "bandpass1.inputs.highpass_freq = highpass_freq\n",
      "bandpass1.inputs.lowpass_freq = lowpass_freq\n",
      "wf.connect(filter2, 'out_res', bandpass1, 'files')\n",
      "\n",
      "bandpass2 = bandpass1.clone(name='bandpass_smooth')\n",
      "wf.connect(filter3, 'out_res', bandpass2, 'files')"
     ],
     "language": "python",
     "metadata": {
      "internals": {},
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bandpass = Node(Function(input_names=['in1', 'in2'],\n",
      "                          output_names=['out_file'],\n",
      "                          function=merge_files,\n",
      "                          imports=imports),\n",
      "                 name='bandpass_merge')\n",
      "wf.connect(bandpass1, 'out_files', bandpass, 'in1')\n",
      "wf.connect(bandpass2, 'out_files', bandpass, 'in2')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wf.write_graph(graph2use='flat')\n",
      "Image(filename='graph.dot.png')"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wf.base_dir = '/mnt/scratch/nipype/'\n",
      "wf.run()"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Optimizing preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "subslide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "#### The Operations\n",
      "\n",
      "- Motion estimation and correction\n",
      "- Noise estimation\n",
      "- Registration\n",
      "- Segmentation\n",
      "- Smoothing\n",
      "- Bandpass filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "# What to watch out for\n",
      "\n",
      "#### The gotchas\n",
      "\n",
      "- Age range \n",
      "- Participant pool\n",
      "- Quality of resting and anatomical data\n",
      "- Normalization template\n",
      "- Distortions\n",
      "- TR or sampling rate or temporal resolution\n",
      "- Spatial resolution\n",
      "- Dummy scans\n",
      "- Spikes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}